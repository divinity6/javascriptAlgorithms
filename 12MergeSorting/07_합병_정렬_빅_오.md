## Big O of mergeSort

- 합병 정렬의 시간 및 공간 복잡도

 | Time Complexity( Best ) | Time Complexity( Average ) | Time Complexity( Worst ) | Space Complexity |          
|:-----------------------:|:--------------------------:|:------------------------:|:----------------:|
|    **O( n log n )**     |      **O( n log n )**      |     **O( n log n )**     |    **O( n )**    |


- 합병 정렬에서는 최적 케이스 , 평균 케이스 , 가장 나쁜 케이스가 **O( n log n )** 으로 모두 같다
  - 당연하지... 해당 배열을 제일 작은단위로 쪼갠다음 병합하니깐...ㅋㅋ


- 버블 정렬은 최적의 케이스에서 데이터가 거의 정렬된 경우가 아니라면 2차 및 제곱 시간이 걸린다
  - 최적 시간에서는 **O( n )** 이라는 선형 시간이 걸림


- 그러나 합병 정렬에서는 예외 케이스가 존재하지 않는다
  - ( 어떤 데이터라도 중요하지 않다. 영향력이 없음 )


- 이 정렬은 계속 나누고 나눈다음 합치고 또 합친다

---

### Time Complexity( 시간 복잡도 ) : O( n log n )

#### log n

- 그런데 어떻게 **n log n** 이 도출된걸까


- 만약 배열에 8 개의 항목이 있다면 이것을 몇번 나누어야할까?( 몇 번을 반복해야 할까 )
  1. 1 개의 배열 8 개
  2. 2 개의 배열 4개 
  3. 4 개의 배열 2개

  
- 총 3번을 나누어야 한다
  - 이것이 바로 big O 이다
  - 밑이 2인 log 인 것( **O( log n )** )
  - 8 개의 요소가 있다면 2를 세번 곱하여 1 , 2 , 4 , 8 이 되는 것이다
  - 나눗셈이 log n


- 배열에서 n 의 길이가 늘어나면 log n 비율로 분할하는 횟수도 늘어난다

#### n

- 그렇다면 n 은 어디에서 나타나는 것일까?


- 각 분할마다, 합병시 **O( n )** 번 비교한다
  - 엘리먼트가 8 개일시 병합시마다 엘리먼트는 8개다
  - 이 갯수는 변하지 않는다( 단지, 나누고 옮길 뿐이다 )
  - 결국, 2개씩의 배열을 비교하는데 각각 O( n )번의 비교가 수행된다


- n 의 길이가 늘어난다면, 합병 정렬이 아닌 합병 알고리즘 자체는 O( n )의 시간 복잡도를 가지게 된다
  - 따라서, 배열 항목이 천개가 있다면 비교를 대략 천번 하게 된다

### 아, 진짜 이건 그림을 그려가면서 보면서 확인해야겠네 진짜...

---

### O( n log n )

- 따라서 결론적으로 **O( n log n )** 이 된다


- **O( log n )** : 나누는 것( 분할하는 수 )
  - 배열이 늘어나면 log n 비율로 분할 횟수가 늘어난다


- **O( n )** : 매번 분할을 수행할 때마다, 합병을 실제로 수행하려면 **O( n )** 비교가 필요하다


- 따라서, 결론적으로 **O( n log n )** 이 된다


- log n 이나 n 처럼 좋지는 않지만 정렬 알고리즘에서는 **사실상 최적의 알고리즘이다**
  - **( 데이터의 특이한 점을 이용할 수 없을 경우 한정 )**


- 즉, 데이터에 구애받지 않는 정렬 알고리즘의 최선은 **O( n log n )** 이다

---

### Space Complexity( 공간 복잡도 )

- 공간 복잡도는 일정한 버블 정렬과 비교하면 다르다


- 배열이 클 수록 합병 정렬에서는 메모리에 더 많은 배열을 저장해야 한다


- 공간을 더 많이 사용해야 하는 것이 대가이다


- 보통은 시간 복잡도를 신경쓰지만, 공간 복잡도를 고려할때는 확실히, 합병 정렬이 더 많은 공간을 차지한다